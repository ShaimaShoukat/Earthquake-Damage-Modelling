{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os \n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "\n",
    "import datetime, warnings, scipy \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.models import Model as KerasModel\n",
    "from keras.layers import Input, Dense, Activation, Reshape\n",
    "from keras.layers import Concatenate, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv('/Users/ShaimaShoukat/Desktop/BDProject/train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv('/Users/ShaimaShoukat/Desktop/BDProject/train_labels.csv', index_col='building_id')\n",
    "test_values = pd.read_csv('/Users/ShaimaShoukat/Desktop/BDProject/test_values.csv', index_col='building_id')\n",
    "\n",
    "#Missing values\n",
    "#dataset = pd.concat(objs=[train_values, test_values], axis=0)\n",
    "\n",
    "train_values = train_values.drop(['geo_level_2_id', 'geo_level_3_id'], axis=1)\n",
    "#test_values = test_values.drop(['geo_level_2_id', 'geo_level_3_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values['geo_level_1_id']= train_values['geo_level_1_id'].astype('object')\n",
    "test_values['geo_level_1_id']= test_values['geo_level_1_id'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting categorical variables to numerical using Label Encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#columns=['foundation_type','land_surface_condition','roof_type','ground_floor_type','other_floor_type','position','plan_configuration','legal_ownership_status']\n",
    "X_cat = train_values.copy()\n",
    "X_cat = train_values.select_dtypes(include=['object'])\n",
    "X_enc = X_cat.copy()\n",
    "labelencoder = LabelEncoder()\n",
    "X_enc = X_enc.apply(LabelEncoder().fit_transform) #\n",
    "train_values = train_values.drop(X_cat.columns, axis=1)\n",
    "train_values = pd.concat([train_values,X_enc], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#over sampling to deal with class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE('minority')\n",
    "train_values_sm,train_labels_sm = smote.fit_sample(train_values,train_labels.values.ravel())\n",
    "X_resampled = pd.DataFrame(train_values_sm, columns=train_values.columns)\n",
    "Y_resampled = pd.DataFrame(train_labels_sm, columns=train_labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geo_level_1_id                            object\n",
       "count_floors_pre_eq                        int64\n",
       "age                                        int64\n",
       "area_percentage                            int64\n",
       "height_percentage                          int64\n",
       "has_superstructure_adobe_mud               int64\n",
       "has_superstructure_mud_mortar_stone        int64\n",
       "has_superstructure_stone_flag              int64\n",
       "has_superstructure_cement_mortar_stone     int64\n",
       "has_superstructure_mud_mortar_brick        int64\n",
       "has_superstructure_cement_mortar_brick     int64\n",
       "has_superstructure_timber                  int64\n",
       "has_superstructure_bamboo                  int64\n",
       "has_superstructure_rc_non_engineered       int64\n",
       "has_superstructure_rc_engineered           int64\n",
       "has_superstructure_other                   int64\n",
       "count_families                             int64\n",
       "has_secondary_use                          int64\n",
       "has_secondary_use_agriculture              int64\n",
       "has_secondary_use_hotel                    int64\n",
       "has_secondary_use_rental                   int64\n",
       "has_secondary_use_institution              int64\n",
       "has_secondary_use_school                   int64\n",
       "has_secondary_use_industry                 int64\n",
       "has_secondary_use_health_post              int64\n",
       "has_secondary_use_gov_office               int64\n",
       "has_secondary_use_use_police               int64\n",
       "has_secondary_use_other                    int64\n",
       "land_surface_condition                    object\n",
       "foundation_type                           object\n",
       "roof_type                                 object\n",
       "ground_floor_type                         object\n",
       "other_floor_type                          object\n",
       "position                                  object\n",
       "plan_configuration                        object\n",
       "legal_ownership_status                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changing the type of categorical variables to 'object'\n",
    "X_resampled['geo_level_1_id']= X_resampled['geo_level_1_id'].astype('object')\n",
    "X_resampled['foundation_type']= X_resampled['foundation_type'].astype('object')\n",
    "X_resampled['land_surface_condition']= X_resampled['land_surface_condition'].astype('object')\n",
    "X_resampled['roof_type']= X_resampled['roof_type'].astype('object')\n",
    "X_resampled['ground_floor_type']= X_resampled['ground_floor_type'].astype('object')\n",
    "X_resampled['other_floor_type']= X_resampled['other_floor_type'].astype('object')\n",
    "X_resampled['position']= X_resampled['position'].astype('object')\n",
    "X_resampled['plan_configuration']= X_resampled['plan_configuration'].astype('object')\n",
    "X_resampled['legal_ownership_status']= X_resampled['legal_ownership_status'].astype('object')\n",
    "\n",
    "X_resampled.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(train_values,train_labels, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>ground_floor_type</th>\n",
       "      <th>other_floor_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1023112</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64407</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>q</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967834</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>v</td>\n",
       "      <td>q</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36669</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>q</td>\n",
       "      <td>f</td>\n",
       "      <td>q</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242842</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            geo_level_1_id  count_floors_pre_eq  age  area_percentage  \\\n",
       "building_id                                                             \n",
       "1023112                 10                    1   20                7   \n",
       "64407                   22                    2   60                7   \n",
       "967834                  26                    2   50                6   \n",
       "36669                    8                    3   50                7   \n",
       "242842                   6                    2   15                8   \n",
       "\n",
       "             height_percentage land_surface_condition foundation_type  \\\n",
       "building_id                                                             \n",
       "1023112                      3                      t               r   \n",
       "64407                        6                      t               r   \n",
       "967834                       5                      t               r   \n",
       "36669                        6                      o               r   \n",
       "242842                       4                      t               r   \n",
       "\n",
       "            roof_type ground_floor_type other_floor_type  ...  \\\n",
       "building_id                                               ...   \n",
       "1023112             n                 f                j  ...   \n",
       "64407               n                 f                q  ...   \n",
       "967834              n                 v                q  ...   \n",
       "36669               q                 f                q  ...   \n",
       "242842              n                 f                x  ...   \n",
       "\n",
       "            has_secondary_use_agriculture has_secondary_use_hotel  \\\n",
       "building_id                                                         \n",
       "1023112                                 0                       0   \n",
       "64407                                   0                       0   \n",
       "967834                                  0                       0   \n",
       "36669                                   0                       0   \n",
       "242842                                  0                       0   \n",
       "\n",
       "             has_secondary_use_rental  has_secondary_use_institution  \\\n",
       "building_id                                                            \n",
       "1023112                             0                              0   \n",
       "64407                               0                              0   \n",
       "967834                              0                              0   \n",
       "36669                               0                              0   \n",
       "242842                              0                              0   \n",
       "\n",
       "             has_secondary_use_school  has_secondary_use_industry  \\\n",
       "building_id                                                         \n",
       "1023112                             0                           0   \n",
       "64407                               0                           0   \n",
       "967834                              0                           0   \n",
       "36669                               0                           0   \n",
       "242842                              0                           0   \n",
       "\n",
       "             has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "building_id                                                                \n",
       "1023112                                  0                             0   \n",
       "64407                                    0                             0   \n",
       "967834                                   0                             0   \n",
       "36669                                    0                             0   \n",
       "242842                                   0                             0   \n",
       "\n",
       "             has_secondary_use_use_police  has_secondary_use_other  \n",
       "building_id                                                         \n",
       "1023112                                 0                        0  \n",
       "64407                                   0                        0  \n",
       "967834                                  0                        0  \n",
       "36669                                   0                        0  \n",
       "242842                                  0                        0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_level_1_id 31\n",
      "land_surface_condition 3\n",
      "foundation_type 5\n",
      "roof_type 3\n",
      "ground_floor_type 5\n",
      "other_floor_type 4\n",
      "position 4\n",
      "plan_configuration 10\n",
      "legal_ownership_status 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_cols=[i for i in X_train.select_dtypes(include=['object'])]\n",
    "\n",
    "for i in embed_cols:\n",
    "    print(i,X_train[i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_cols=[i for i in X_train.select_dtypes(include=['object'])]\n",
    "\n",
    "#converting data to list format to match the network structure\n",
    "def preproc(X_train, X_val, X_test):\n",
    "\n",
    "    input_list_train = []\n",
    "    input_list_val = []\n",
    "    input_list_test = []\n",
    "    \n",
    "    #the cols to be embedded: rescaling to range [0, # values)\n",
    "    for c in embed_cols:\n",
    "        raw_vals = np.unique(X_train[c])\n",
    "        val_map = {}\n",
    "        for i in range(len(raw_vals)):\n",
    "            val_map[raw_vals[i]] = i       \n",
    "        input_list_train.append(X_train[c].map(val_map).values)\n",
    "        input_list_val.append(X_val[c].map(val_map).fillna(0).values)\n",
    "        input_list_test.append(X_test[c].map(val_map).fillna(0).values)\n",
    "     \n",
    "    #the rest of the columns\n",
    "    other_cols = [c for c in X_train.columns if (not c in embed_cols)]\n",
    "    input_list_train.append(X_train[other_cols].values)\n",
    "    input_list_val.append(X_val[other_cols].values)\n",
    "    input_list_test.append(X_test[other_cols].values)\n",
    "    \n",
    "    return input_list_train, input_list_val, input_list_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorica Variable: geo_level_1_id Unique Categories: 31 Embedding Size: 16\n",
      "Categorica Variable: land_surface_condition Unique Categories: 3 Embedding Size: 2\n",
      "Categorica Variable: foundation_type Unique Categories: 5 Embedding Size: 3\n",
      "Categorica Variable: roof_type Unique Categories: 3 Embedding Size: 2\n",
      "Categorica Variable: ground_floor_type Unique Categories: 5 Embedding Size: 3\n",
      "Categorica Variable: other_floor_type Unique Categories: 4 Embedding Size: 2\n",
      "Categorica Variable: position Unique Categories: 4 Embedding Size: 2\n",
      "Categorica Variable: plan_configuration Unique Categories: 10 Embedding Size: 5\n",
      "Categorica Variable: legal_ownership_status Unique Categories: 4 Embedding Size: 2\n"
     ]
    }
   ],
   "source": [
    "for categorical_var in X_train.select_dtypes(include=['object']):\n",
    "    \n",
    "    cat_emb_name= categorical_var.replace(\" \", \"\")+'_Embedding'\n",
    "  \n",
    "    no_of_unique_cat  = X_train[categorical_var].nunique()\n",
    "    embedding_size = int(min(np.ceil((no_of_unique_cat)/2), 50 ))\n",
    "  \n",
    "    print('Categorica Variable:', categorical_var,\n",
    "        'Unique Categories:', no_of_unique_cat,\n",
    "        'Embedding Size:', embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_geo_level_1_id\n",
      "Input_land_surface_condition\n",
      "Input_foundation_type\n",
      "Input_roof_type\n",
      "Input_ground_floor_type\n",
      "Input_other_floor_type\n",
      "Input_position\n",
      "Input_plan_configuration\n",
      "Input_legal_ownership_status\n"
     ]
    }
   ],
   "source": [
    "for categorical_var in X_train.select_dtypes(include=['object']):\n",
    "    \n",
    "    input_name= 'Input_' + categorical_var.replace(\" \", \"\")\n",
    "    print(input_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating embeddings for each of the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_models=[]\n",
    "output_embeddings=[]\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "for categorical_var in X_train.select_dtypes(include=['object']):\n",
    "    \n",
    "    #Name of the categorical variable that will be used in the Keras Embedding layer\n",
    "    cat_emb_name= categorical_var.replace(\" \", \"\")+'_Embedding'\n",
    "  \n",
    "    # Define the embedding_size\n",
    "    no_of_unique_cat  = X_train[categorical_var].nunique()\n",
    "    embedding_size = int(min(np.ceil((no_of_unique_cat)/2), 50 ))\n",
    "  \n",
    "    #One Embedding Layer for each categorical variable\n",
    "    input_model = Input(shape=(1,))\n",
    "    output_model = Embedding(no_of_unique_cat, embedding_size, name=cat_emb_name)(input_model)\n",
    "    output_model = Reshape(target_shape=(embedding_size,))(output_model)    \n",
    "  \n",
    "    #Appending all the categorical inputs\n",
    "    input_models.append(input_model)\n",
    "  \n",
    "    #Appending all the embeddings\n",
    "    output_embeddings.append(output_model)\n",
    "  \n",
    "#Other non-categorical data columns (numerical). \n",
    "#I define single another network for the other columns and add them to our models list.\n",
    "input_numeric = Input(shape=(len(X_train.select_dtypes(include=numerics).columns.tolist()),))\n",
    "embedding_numeric = Dense(128)(input_numeric) \n",
    "input_models.append(input_numeric)\n",
    "output_embeddings.append(embedding_numeric)\n",
    "\n",
    "#At the end we concatenate altogther and add other Dense layers\n",
    "output = Concatenate()(output_embeddings)\n",
    "output = Dense(1000, kernel_initializer=\"uniform\")(output)\n",
    "output = Activation('relu')(output)\n",
    "output= Dropout(0.4)(output)\n",
    "output = Dense(512, kernel_initializer=\"uniform\")(output)\n",
    "output = Activation('relu')(output)\n",
    "output= Dropout(0.3)(output)\n",
    "output = Dense(4, activation='softmax')(output)\n",
    "\n",
    "model = Model(inputs=input_models, outputs=output)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam',metrics=['sparse_categorical_crossentropy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 208480 samples, validate on 52121 samples\n",
      "Epoch 1/5\n",
      " - 167s - loss: 1.1921 - sparse_categorical_crossentropy: 0.8181 - val_loss: 0.7795 - val_sparse_categorical_crossentropy: 0.7795\n",
      "Epoch 2/5\n",
      " - 129s - loss: 1.1886 - sparse_categorical_crossentropy: 0.8167 - val_loss: 0.8136 - val_sparse_categorical_crossentropy: 0.8136\n",
      "Epoch 3/5\n",
      " - 88s - loss: 1.1911 - sparse_categorical_crossentropy: 0.8179 - val_loss: 0.8225 - val_sparse_categorical_crossentropy: 0.8225\n",
      "Epoch 4/5\n",
      " - 93s - loss: 1.1868 - sparse_categorical_crossentropy: 0.8159 - val_loss: 0.7876 - val_sparse_categorical_crossentropy: 0.7876\n",
      "Epoch 5/5\n",
      " - 87s - loss: 1.1820 - sparse_categorical_crossentropy: 0.8122 - val_loss: 0.7754 - val_sparse_categorical_crossentropy: 0.7754\n"
     ]
    }
   ],
   "source": [
    "class_weights = {1: 1.75,\n",
    "            2: 1.0,\n",
    "            3: 3.03}\n",
    "history  =  model.fit(X_train_list,Y_train,validation_data=(X_val_list,Y_val) , epochs =  5,verbose=2,class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = model.predict(X_val_list)\n",
    "y_prob = model.predict(X_val_list)   # Get class probability vector for each sample\n",
    "y_class = y_prob.argmax(axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# Save the model\n",
    "model.save('Ann_Final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "new_model = keras.models.load_model('Ann_Final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52121/52121 [==============================] - 5s 94us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.43      0.51      5170\n",
      "           2       0.73      0.53      0.62     29487\n",
      "           3       0.52      0.81      0.64     17464\n",
      "\n",
      "    accuracy                           0.62     52121\n",
      "   macro avg       0.62      0.59      0.59     52121\n",
      "weighted avg       0.65      0.62      0.61     52121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_val_list, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(Y_val, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "class_labels = ['low','medium','high']\n",
    "cm = metrics.confusion_matrix(Y_val, y_pred_bool)\n",
    "\n",
    "    \n",
    "# plot confusin matrix\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.grid(b=False)\n",
    "plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "# get classification report\n",
    "print('-------------------------')\n",
    "print('| Classifiction Report |')\n",
    "classification_report = metrics.classification_report(Y_val, y_pred_bool)\n",
    "print(classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_val, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MicroP = (924+25900+7993)/(924+25900+7993+267+15+9456+4211+35+3320)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(new_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86868/86868 [==============================] - 118s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(X_test_list, batch_size=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_bool = np.argmax(test_pred, axis=1)\n",
    "submission_format = pd.read_csv('/Users/ShaimaShoukat/Desktop/BDProject/submission_format.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame(data=test_pred_bool,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.to_csv('Ann_weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#over sampling \n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE('minority')\n",
    "train_values_sm,train_labels_sm = smote.fit_sample(new_train,train_labels.values.ravel())\n",
    "print(train_values_sm.shape,train_labels_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "References:\n",
    "1)https://github.com/mmortazavi/EntityEmbedding-Working_Example/blob/master/EntityEmbedding.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
